{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"database.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM Reviews\", con)\n",
    "df.index = df[\"Id\"]\n",
    "df[\"Text\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568454</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "Id                                                                            \n",
       "1            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "2            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "3            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "4            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "5            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...        ...         ...             ...                              ...   \n",
       "568450  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568451  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568452  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568453  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568454  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "Id                                                                        \n",
       "1                          1                       1      5  1303862400   \n",
       "2                          0                       0      1  1346976000   \n",
       "3                          1                       1      4  1219017600   \n",
       "4                          3                       3      2  1307923200   \n",
       "5                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568450                     0                       0      5  1299628800   \n",
       "568451                     0                       0      2  1331251200   \n",
       "568452                     2                       2      5  1329782400   \n",
       "568453                     1                       1      5  1331596800   \n",
       "568454                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "Id                                           \n",
       "1                    Good Quality Dog Food   \n",
       "2                        Not as Advertised   \n",
       "3                    \"Delight\" says it all   \n",
       "4                           Cough Medicine   \n",
       "5                              Great taffy   \n",
       "...                                    ...   \n",
       "568450                 Will not do without   \n",
       "568451                        disappointed   \n",
       "568452            Perfect for our maltipoo   \n",
       "568453  Favorite Training and reward treat   \n",
       "568454                         Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "Id                                                         \n",
       "1       I have bought several of the Vitality canned d...  \n",
       "2       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "3       This is a confection that has been around a fe...  \n",
       "4       If you are looking for the secret ingredient i...  \n",
       "5       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568450  Great for sesame chicken..this is a good if no...  \n",
       "568451  I'm disappointed with the flavor. The chocolat...  \n",
       "568452  These stars are small, so you can give 10-15 o...  \n",
       "568453  These are the BEST treats for training and rew...  \n",
       "568454  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[568454 rows x 10 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis\\' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Text\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "1              1\n",
       "2              2\n",
       "3              3\n",
       "4              4\n",
       "5              5\n",
       "           ...  \n",
       "568450    568450\n",
       "568451    568451\n",
       "568452    568452\n",
       "568453    568453\n",
       "568454    568454\n",
       "Name: Id, Length: 568454, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dftrain, dftest = train_test_split(df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}  \n",
    "word_encoding = 1\n",
    "def one_hot_encoding(text):\n",
    "    global word_encoding\n",
    "\n",
    "    words = text.lower().split(\" \") \n",
    "    encoding = []  \n",
    "\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            code = vocab[word]  \n",
    "            encoding.append(code) \n",
    "        else:\n",
    "            vocab[word] = word_encoding\n",
    "            encoding.append(word_encoding)\n",
    "            word_encoding += 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-ae9b623f06b5>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dftrain[\"encoding\"] = [one_hot_encoding(dftrain.iloc[i,8]) for i in range(454763)]\n"
     ]
    }
   ],
   "source": [
    "dftrain[\"encoding\"] = [one_hot_encoding(dftrain.iloc[i,8]) for i in range(454763)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-d17ab49e3f69>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dftest[\"encoding\"] = [one_hot_encoding(dftrain.iloc[i,8]) for i in range(113691)]\n"
     ]
    }
   ],
   "source": [
    "dftest[\"encoding\"] = [one_hot_encoding(dftrain.iloc[i,8]) for i in range(113691)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrainnew = dftrain[\"encoding\"]\n",
    "dftestnew = dftest[\"encoding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113691"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain_labels = dftrain[\"Score\"]\n",
    "dftest_labels = dftest[\"Score\"]\n",
    "len(dftest_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = []\n",
    "for i in dftrain_labels.values:\n",
    "    ar.append(i)\n",
    "dftrain_labels_encoding = np.array(ar)\n",
    "\n",
    "ar1 = []\n",
    "for i in dftest_labels.values:\n",
    "    ar1.append(i)\n",
    "dftest_labels_encoding = np.array(ar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-57c48caa876f>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dftrainnew_encoding = np.asarray(dftrainnew.values.tolist())\n",
      "<ipython-input-53-57c48caa876f>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dftestnew_encoding = np.asarray(dftestnew.values.tolist())\n"
     ]
    }
   ],
   "source": [
    "dftrainnew_encoding = np.asarray(dftrainnew.values.tolist())\n",
    "dftestnew_encoding = np.asarray(dftestnew.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 16, 3, 10, 22, 23, 24, 25, 26, 27, 2, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 25, 10, 45, 36, 46, 47, 48, 49, 50, 51, 52, 53]),\n",
       "       list([54, 4, 55, 25, 56, 57, 58, 59, 60, 61, 62, 63, 64, 63, 65, 66, 67, 7, 10, 68, 69, 17, 70, 63, 65, 71, 46, 72, 61, 73, 74, 75, 46, 10, 76, 77, 78, 70, 79, 80, 81, 82, 83, 10, 84, 52, 85, 71, 46, 72, 61, 13, 86, 38, 87, 70, 1, 88, 89, 17, 44, 25, 10, 90, 70, 91, 92, 93, 94, 95, 96, 7, 97, 98, 99, 37, 100, 101, 52, 102, 103, 104, 105, 106, 95, 107, 108, 57, 100, 109, 110, 111, 33, 112, 29, 113, 114, 23, 113, 115, 114, 116, 117]),\n",
       "       list([47, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 38, 129, 130, 131, 20, 132, 133, 134, 135, 136, 127, 137, 4, 138, 25, 123, 124, 139, 16, 140, 141, 127, 142, 143, 144, 134, 46, 145, 146, 127, 17, 147, 148, 149, 134, 150, 25, 145, 151, 13, 86, 148, 152, 95, 153, 41, 10, 154, 7, 101, 155, 156, 41, 4, 157, 149, 120, 134, 52, 158, 159, 160, 10, 161, 162, 46, 4, 163, 164, 165, 52, 166, 137, 10, 167, 168, 169, 29, 170, 171, 41, 172, 47, 120, 173, 174, 10, 175, 176, 177, 13, 178, 10, 175, 179, 180, 181, 25, 182, 23, 183, 162, 23, 184, 185, 141, 186, 187, 186, 188, 47, 120, 189, 16, 46, 190, 191, 192, 100, 65, 193, 52, 194, 195, 196, 197, 141, 198, 199, 16, 200, 201, 47, 202, 70, 1, 89, 49, 71, 46, 203, 13, 86, 38, 204, 205, 70, 206, 207, 4, 208, 209, 23, 205, 113, 120, 17, 141, 210, 211, 212, 213, 214, 10, 215, 216, 46, 4, 217, 54, 218, 16, 219, 46, 4, 220, 221, 23, 222, 16, 46, 10, 223, 41, 10, 224, 225, 226, 227, 228, 136, 229, 230, 47, 120, 17, 38, 177, 231, 232, 16, 233, 127, 234, 235, 236, 10, 182, 237, 23, 238, 10, 239, 240, 10, 241, 242, 243, 46, 145, 244, 127, 245, 246, 141, 10, 175, 95, 247, 248, 205, 63, 249, 122, 10, 175, 250, 41, 251, 47, 120, 234, 252, 253, 10, 198, 254, 255, 49, 4, 256, 41, 10, 257, 23, 258, 259, 23, 260, 127, 54, 246, 141, 16, 30, 261, 7, 127, 262, 263, 145, 123, 124, 139, 177, 13, 264, 13, 101, 52, 265, 266, 41, 267]),\n",
       "       ...,\n",
       "       list([1, 17, 47, 15643, 269, 46, 10, 2671, 10, 138, 17, 222403, 1222, 320, 5825, 205, 2700, 4, 38611, 141, 2169, 893, 252, 1, 282, 1164, 517, 16220, 177, 58, 414, 101, 305, 98, 305, 58, 830, 873, 1, 89, 763, 1743, 49, 4, 329, 69089, 1434, 1238, 23, 840, 36482, 16, 49, 3232, 295, 1752, 10, 89, 46, 4, 218, 20, 397, 29, 2375, 20987, 2228, 996, 807, 3248]),\n",
       "       list([47, 1108, 49, 2147, 541, 119, 57, 100, 467, 505, 30, 134, 195, 25, 4, 1202, 2932, 237, 1099, 70, 1059, 49, 1931, 2232, 4769, 328, 23, 7793, 61, 642, 9, 13, 414, 1362, 92, 65, 4, 12340, 1141, 70, 536, 314, 41055, 61, 63, 37, 138, 785, 23, 65, 1157, 52, 1196, 148, 10, 280, 61, 333, 880, 63, 65, 285, 2416, 150, 732, 17, 19800, 320, 236, 505, 1684, 365772, 92, 8887, 46, 505, 1468, 23, 2640, 865, 61, 100, 879, 996, 59, 185, 25, 2924]),\n",
       "       list([13, 456, 5588, 44036, 789, 305, 13, 49, 41653, 10, 10954, 23, 49, 17251, 104, 463, 18038, 591, 41322, 114, 25545, 10, 779, 447713, 13, 2840, 52, 521, 16, 4, 3062, 13, 446, 10, 591, 46, 10, 223, 41, 4, 1686, 136, 16, 1613, 46, 10, 11812, 16, 284, 54, 141, 6081, 276, 424, 1819, 136, 6, 288, 13, 262, 973, 102, 47, 527, 5503, 83, 10, 1054, 70, 517, 248914, 114, 38, 40788, 397, 609, 16, 284, 54, 141, 6081, 789, 52, 2377, 10, 242, 25, 10, 3843, 7668, 4, 7473, 148, 47, 3075, 9561, 517, 276, 3893, 1156, 16, 447714, 205, 2700, 1782, 873, 1, 2804, 58, 206, 765, 5318, 23, 37, 4830, 517, 1380, 4, 3062, 136, 2011, 893, 683, 1453, 205, 58, 314, 141, 16, 20, 38, 1358, 58, 3062, 11751])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrainnew_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113691"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dftestnew_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 4, ..., 5, 5, 3], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain_labels_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113691"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dftest_labels_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    51,    52,    53],\n",
       "       [    0,     0,     0, ...,   114,   116,   117],\n",
       "       [  134,   150,    25, ...,   266,    41,   267],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,   113, 31431, 21413],\n",
       "       [    0,     0,     0, ...,  2737,    65,  2255],\n",
       "       [    0,     0,     0, ...,  1563,   104,  5775]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrainnew_encoding = tf.keras.preprocessing.sequence.pad_sequences(dftrainnew_encoding, 250)\n",
    "dftestnew_encoding = tf.keras.preprocessing.sequence.pad_sequences(dftestnew_encoding, 250)\n",
    "dftestnew_encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(113691, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrainlabels = tf.one_hot(dftrain_labels_encoding, 6)\n",
    "dftestlabels = tf.one_hot(dftest_labels_encoding, 6)\n",
    "dftestlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 500000\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 100),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dense(6, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 100)         50000000  \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               117248    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,118,022\n",
      "Trainable params: 50,118,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2843/2843 [==============================] - 3671s 1s/step - loss: 0.7379 - acc: 0.7301 - val_loss: 0.6275 - val_acc: 0.7700\n",
      "Epoch 2/5\n",
      "2843/2843 [==============================] - 33449s 12s/step - loss: 0.4800 - acc: 0.8250 - val_loss: 0.5895 - val_acc: 0.7969\n",
      "Epoch 3/5\n",
      "2843/2843 [==============================] - 3981s 1s/step - loss: 0.3070 - acc: 0.8903 - val_loss: 0.6304 - val_acc: 0.7997\n",
      "Epoch 4/5\n",
      "2843/2843 [==============================] - 8470s 3s/step - loss: 0.1866 - acc: 0.9346 - val_loss: 0.7550 - val_acc: 0.7929\n",
      "Epoch 5/5\n",
      "2843/2843 [==============================] - 4466s 2s/step - loss: 0.1164 - acc: 0.9597 - val_loss: 0.8917 - val_acc: 0.8005\n"
     ]
    }
   ],
   "source": [
    "history = model.fit( tf.convert_to_tensor(dftrainnew_encoding),  tf.convert_to_tensor(dftrainlabels), batch_size=128, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3553/3553 [==============================] - 273s 77ms/step - loss: 5.1597 - acc: 0.4490\n",
      "[5.159664154052734, 0.4489537477493286]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(tf.convert_to_tensor(dftestnew_encoding), dftestlabels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0, 1992, 1238])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_text(text):\n",
    "    tokens = tf.keras.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens = [vocab[word] if word in vocab else 0 for word in tokens]\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences([tokens], 250)[0]\n",
    "encode_text(\"Awesome service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.86436886, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1,250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred) \n",
    "    return max(result[0]), list(result[0]).index(max(result[0]))\n",
    "predict(\"Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as Jumbo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.91233927, 4)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis\\' The Lion, The Witch, and The Wardrobe - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.99311304, 0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Hell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9986723, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Stale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.85214335, 4)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
